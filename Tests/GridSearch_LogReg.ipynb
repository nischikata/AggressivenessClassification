{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 31.622776601683793}\n",
      "Best score is 0.884522854852\n"
     ]
    }
   ],
   "source": [
    "from Utils.setupDataset import get_dataset, combine_datasets\n",
    "from Utils.feature_vector import get_feature_names\n",
    "\n",
    "fnames = get_feature_names()\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "fnames = get_feature_names()\n",
    "\n",
    "m_dataset = get_dataset(\"Datasets/dataset.pickle\")\n",
    "w_dataset = get_dataset(\"Datasets/wiki_dataset.pickle\")\n",
    "\n",
    "\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression(penalty='l1')\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "\n",
    "X = w_dataset[\"data\"] \n",
    "y = w_dataset[\"target\"]\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penalty L1:\n",
    "# my dataset:\n",
    "Tuned Logistic Regression Parameters: {'C': 2275.8459260747909}\n",
    "Best score is 0.816247582205\n",
    "\n",
    "Tuned Logistic Regression Parameters: {'C': 268.26957952797272}\n",
    "Best score is 0.817214700193\n",
    "\n",
    "Tuned Logistic Regression Parameters: {'C': 19306.977288832535}\n",
    "Best score is 0.816247582205\n",
    "\n",
    "# wiki dataset:\n",
    "Tuned Logistic Regression Parameters: {'C': 268.26957952797272}\n",
    "* Best score is 0.884121892542"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penalty L2\n",
    "\n",
    "# my dataset:\n",
    "Tuned Logistic Regression Parameters: {'C': 1389495.494373136}\n",
    "Best score is 0.817214700193\n",
    "\n",
    "* Tuned Logistic Regression Parameters: {'C': 19306.977288832535}\n",
    "Best score is 0.81914893617\n",
    "\n",
    "Tuned Logistic Regression Parameters: {'C': 100000000.0}\n",
    "Best score is 0.817214700193\n",
    "\n",
    "Tuned Logistic Regression Parameters: {'C': 19306.977288832535}\n",
    "Best score is 0.818181818182\n",
    "\n",
    "# wiki dataset:\n",
    "Tuned Logistic Regression Parameters: {'C': 1389495.494373136}\n",
    "Best score is 0.862670408982\n",
    "\n",
    "* Tuned Logistic Regression Parameters: {'C': 19306.977288832535}\n",
    "Best score is 0.861868484362\n",
    "\n",
    "Tuned Logistic Regression Parameters: {'C': 1389495.494373136}\n",
    "Best score is 0.861066559743\n",
    "\n",
    "Tuned Logistic Regression Parameters: {'C': 0.051794746792312128}\n",
    "Best score is 0.861868484362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
